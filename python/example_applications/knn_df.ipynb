{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Nearest Neighbors of Tabular Data\n",
    "In this notebook, we compute the nearest neighbors of different row items in a tabular dataset (loaded as a `pd.DataFrame`) using K-Nearest Neighbors and FAISS trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "!pip install faiss  # Installs the FAISS library\n",
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "K_NEIGHBORS = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read CSV File Into Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# \"Read file\" (dummy data)\n",
    "df = pd.DataFrame({c: np.random.randint(low=1, high=190, size=10000) for c in ['a', 'b']})\n",
    "df #pd.read_csv(FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weight Features With User Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get size of data to provide user with weights\n",
    "n_cols = df.values.shape[1]  # Get number of columns\n",
    "print(\"Please enter {} weights, one for each column:\".format(n_cols))\n",
    "query = input(\"Please enter {} numbers in list format, e.g. {} \\n -->\".format(n_cols, [i for i in range(n_cols)]))\n",
    "weights = np.array(eval(query))  # Reads as list, and converts to NumPy array\n",
    "print(\"Weights are: {}\".format(weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now \"weight the features\"\n",
    "X = df.values  # Creates a NumPy array\n",
    "X_norm = X * weights  # Scales values by weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Neighbors Using [K-Nearest Neighbor Objects](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.NearestNeighbors.html)\n",
    "KNN objects can be used to compute nearest neighbors using a variety of distance metrics, which can be helpful for instances where data has different scales (e.g. Mahalanobis distance), is gridded (Manhattan distance), or has other unique constraints.  Below, we will implement KNN objects with the `sklearn` Python libary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create K-Nearest Neighbors object\n",
    "knn = NearestNeighbors(n_neighbors=K_NEIGHBORS, metric=\"minkowski\", p=2)\n",
    "knn.fit(X_norm)  # Fit the knn object to the data\n",
    "neighbor_idx = knn.kneighbors(X_norm, K_NEIGHBORS+1, return_distance=False)[:, 1:]  # Can't take yourself\n",
    "neighbor_dict = {i: k for i, k in enumerate(neighbor_idx)}  # Indexed by X_norm\n",
    "\n",
    "neighbor_dict\n",
    "# NOTE: Can also use metric=\"mahalanobis\" to use distance that scales for each dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Neighbors Using [FAISS Trees](https://github.com/facebookresearch/faiss)\n",
    "FAISS trees are especially helpful for running large queries.  These operations are run in C in order to improve runtime, and can result in signicantly faster queries for large datasets/high dimensions.\n",
    "\n",
    "Below, we'll show how to query neighbors using L2-norms (Euclidean distance), implemented with the `faiss` Python libary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaissKNeighbors:\n",
    "    \"\"\"An implementation of FAISS trees.\n",
    "\n",
    "    Parameters:\n",
    "        k (int): The number of neighbors we consider for the FAISS tree.\n",
    "    \"\"\"\n",
    "    def __init__(self, k=50):\n",
    "        self.index = None\n",
    "        self.k = k\n",
    "\n",
    "    def fit(self, X):\n",
    "        \"\"\"Function to fit the FAISS tree.\n",
    "\n",
    "        Parameters:\n",
    "            X (np.array):  Array of shape (N, d), where N is the number of\n",
    "                samples and d is the dimension of hte data.  Note that the\n",
    "                array must be of type np.float32.\n",
    "        \"\"\"\n",
    "        self.index = faiss.IndexFlatL2(X.shape[1])\n",
    "        self.index.add(X.astype(np.float32))\n",
    "\n",
    "    def query(self, X, k=None):\n",
    "        \"\"\"Function to query the neighbors of the FAISS tree.\n",
    "\n",
    "        Parameters:\n",
    "            X (np.array):  Array of shape (N, D), where N is the number of\n",
    "                samples, and D is the dimension of the features.\n",
    "            k (int):  If provided, the number of neighbors to compute.  Defaults\n",
    "                to None, in which case self.k is used as the number of neighbors.\n",
    "\n",
    "        Returns:\n",
    "            indices (np.array): Array of shape (N, K), where N is the number of\n",
    "                samples, and K is the number of nearest neighbors to be computed.\n",
    "                The ith row corresponds to the k-nearest neighbors of the ith\n",
    "                sample.\n",
    "        \"\"\"\n",
    "        # Set number of neighbors\n",
    "        if k is None:  # Use default number of neighbors\n",
    "            k = self.k\n",
    "\n",
    "        # Query and return nearest neighbors\n",
    "        _, indices = self.index.search(X.astype(np.float32), k=k)\n",
    "        return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to convert array to C-order\n",
    "X_norm = X_norm.copy(order=\"C\")\n",
    "\n",
    "# Fit the FAISS tree\n",
    "faiss_tree = FaissKNeighbors(k=K_NEIGHBORS+1)  # Creates the FAISS tree\n",
    "faiss_tree.fit(X_norm)  # Fits using L2 norm (Euclidean distance)\n",
    "\n",
    "# Now query neighbors of the FAISS tree\n",
    "neighbor_idx = faiss_tree.query(X_norm)[:, 1:]\n",
    "neighbor_dict = {i: k for i, k in enumerate(neighbor_idx)}  # Indexed by X_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Put It All Together As a Function!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_k_nearest(f_csv, kneighbors=5, use_faiss=False, metric=\"minkowski\", p=2):\n",
    "    \n",
    "    # Read csv file into pandas DataFrame\n",
    "    df = pd.read_csv(f_csv)    \n",
    "    \n",
    "    # Get size of data to provide user with weights\n",
    "    n_cols = df.values.shape[1]  # Get number of columns\n",
    "    print(\"Please enter {} weights, one for each column:\".format(n_cols))\n",
    "    query = input(\"Please enter {} numbers in list format, e.g. {} \\n -->\".format(n_cols, [i for i in range(n_cols)]))\n",
    "    weights = np.array(eval(query))  # Reads as list, and converts to NumPy array\n",
    "    print(\"Weights are: {}\".format(weights))\n",
    "    \n",
    "    # Now \"weight the features\"\n",
    "    X = df.values  # Creates a NumPy array\n",
    "    X_norm = X * weights  # Scales values by weights\n",
    "    \n",
    "    # Use KNN\n",
    "    if not use_faiss:\n",
    "        # Create K-Nearest Neighbors object\n",
    "        knn = NearestNeighbors(n_neighbors=kneighbors, metric=metric, p=p)\n",
    "        knn.fit(X_norm)  # Fit the knn object to the data\n",
    "        \n",
    "        # Now query neighbors of the KNN tree (NOTE: closest neighbor may be point itself)\n",
    "        neighbor_idx = knn.kneighbors(X_norm, kneighbors+1, return_distance=False)[:, 1:]\n",
    "        neighbor_dict = {i: k for i, k in enumerate(neighbor_idx)}  # Indexed by X_norm\n",
    "    \n",
    "    # Use FAISS tree\n",
    "    else:\n",
    "        # Need to convert array to C-order\n",
    "        X_norm = X_norm.copy(order=\"C\")\n",
    "\n",
    "        # Fit the FAISS tree\n",
    "        faiss_tree = FaissKNeighbors(k=kneighbors+1)  # Creates the FAISS tree\n",
    "        faiss_tree.fit(X_norm)  # Fits using L2 norm (Euclidean distance)\n",
    "\n",
    "        # Now query neighbors of the FAISS trees\n",
    "        neighbor_idx = faiss_tree.query(X_norm)[:, 1:]\n",
    "        neighbor_dict = {i: k for i, k in enumerate(neighbor_idx)}  # Indexed by X_norm\n",
    "    \n",
    "    return neighbor_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "interreplay",
   "language": "python",
   "name": "interreplay"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
