{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![TensorFlow](notebook_diagrams/tensorflow.png)\n",
    "\n",
    "# Tutorial for TensorFlow\n",
    "TensorFlow is a library for creating scalable deep learning models that are efficient and compact.  It is widely used across deep learning applications, and is actually used as the backend for Keras.  Compared to **PyTorch** and **Keras**, it is the most computationally-efficient library of these three popular frameworks, and because of this it is quite often used for deploying models.\n",
    "\n",
    "The key element behind TensorFlow's efficiency is the [computation graph](https://medium.com/ai%C2%B3-theory-practice-business/tensorflow-1-0-vs-2-0-part-1-computational-graphs-4bb6e31c1a0f).  This is a directed graph where different nodes (circles on the diagram below) represent different TensorFlow operations, and edges (arrows on the diagram below) represent tensors \"flowing\" between operations.  This graph is important, because by default different operations and data structures only serve as symbolic variables to the nodes and edges in this graph, so this graph is where all computation actually occurs.\n",
    "\n",
    "![tf-comp-graph](notebook_diagrams/tf_comp_graph.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Block\n",
    "**NOTE**: For this tutorial, we'll be using TensorFlow 2.1.0.  This version is the most recent version of this package, and therefore contains the most advanced capabilities.  We strongly recommend only learning TensorFlow 2.0 (not 1.14 or 1.15), as many functionalities from TensorFlow 1 will soon become deprecated.\n",
    "\n",
    "TensorFlow is a large Python package, particularly when cuda (which is used when making GPU computations) bindings are installed.  If you know you will only be using a CPU for TensorFlow, it is advisable that you install a CPU-only version of this package.\n",
    "\n",
    "**Known Windows 8 Issue**: If you are running this on Windows 8, please see [this Stack Overflow post](https://stackoverflow.com/questions/46736219/installing-tensorflow-gpu-on-win-8).  If you're running this on AWS, you won't need to worry about this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install any existing installations of TensorFlow\n",
    "! conda uninstall tensorflow\n",
    "\n",
    "# Upgrade pip, another popular Python package manager\n",
    "! pip install --upgrade pip\n",
    "\n",
    "# Install tensorflow 2.1 using pip\n",
    "! pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Installation by Getting TensorFlow Version\n",
    "In general, this a good way to check that our packages are compatible and are the versions we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show tensorflow-related information\n",
    "! pip show tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import TensorFlow and Turn On Eager Execution\n",
    "**Eager execution** is a feature in TensorFlow that enables for operations on tensors to be executed immediately.  This is important because by default (without eager execution), tensors and operations are not concrete executables, and only point to nodes and edges in the computation graph.  With eager execution, however, these operations and tensors point to concrete values.\n",
    "\n",
    "For debugging, and if you want to integrate other packages into TensorFlow (we'll discuss the integration of numpy with TensorFlow below), you should be using eager execution.  The next block shows how you can check if TensorFlow is in eager execution mode, and if it isn't how you can change it to be so.\n",
    "\n",
    "If you would like to learn more about the mechanics of eager execution, take a look at [this tutorial](https://www.tensorflow.org/guide/eager)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import TensorFlow\n",
    "import tensorflow as tf  # Don't need to do \"as tf\", but typically just done out of convention\n",
    "\n",
    "# Check if eager execution is on, and if not, turn it on\n",
    "if not tf.executing_eagerly():\n",
    "    tf.enable_eager_execution()\n",
    "print(\"Eager execution: %s\" % (tf.executing_eagerly()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install/Upgrade Other Packages to Avoid Version Clash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install/import other image processing libraries\n",
    "! pip install Pillow\n",
    "! pip install --upgrade scipy\n",
    "! pip install --upgrade scikit-learn\n",
    "! pip install imageio\n",
    "\n",
    "# Install opencv-python using conda\n",
    "! pip uninstall opencv-python -y\n",
    "! sudo apt install libgl1-mesa-glx -y\n",
    "! conda install -c conda-forge opencv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Other Packages for Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Numerical processing\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "# Image processing\n",
    "import cv2 as cv\n",
    "\n",
    "# For file paths\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Introduction to the Tensor Data Type\n",
    "In addition to the computation graph, TensorFlow is also able to create efficient code for deep learning using the `tensor` data type, an object they created that optimizes the flow of information through computation graphs.  This object is similar to the numpy `nd_array` object we saw with numpy, and is used to store and transform numerical data through different computation graphs/deep learning pipelines.\n",
    "\n",
    "A TensorFlow `tensor` has two different properties:\n",
    "\n",
    "1. A data type (e.g. `int32`, `float32`)\n",
    "\n",
    "2. A shape (which also determines **Rank**, or the number of dimensions of a `tensor` object).\n",
    "\n",
    "Like numpy `nd_array` objects, TensorFlow `tensor` objects must have the same data type for all elements in the tensor.  There are many kinds of `tf.tensor` objects, but the only **mutable** (changeable) of these objects is `tf.Variable`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rank 0 Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create some TensorFlow tensors!\n",
    "mammal = tf.Variable(\"Elephant\", tf.string)\n",
    "ignition = tf.Variable(451, tf.int16)\n",
    "floating = tf.Variable(3.14159265359, tf.float64)\n",
    "its_complicated = tf.Variable(12.3 - 4.85j, tf.complex64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rank 1 Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create some TensorFlow tensors!\n",
    "mystr = tf.Variable([\"Hello\"], tf.string)\n",
    "cool_numbers  = tf.Variable([3.14159, 2.71828], tf.float32)\n",
    "first_primes = tf.Variable([2, 3, 5, 7, 11], tf.int32)\n",
    "its_very_complicated = tf.Variable([12.3 - 4.85j, 7.5 - 6.23j], tf.complex64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rank 2 Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create some TensorFlow tensors!\n",
    "mymat = tf.Variable([[7],[11]], tf.int16)\n",
    "myxor = tf.Variable([[False, True],[True, False]], tf.bool)\n",
    "linear_squares = tf.Variable([[4], [9], [16], [25]], tf.int32)\n",
    "squarish_squares = tf.Variable([ [4, 9], [16, 25] ], tf.int32)\n",
    "rank_of_squares = tf.rank(squarish_squares)\n",
    "mymatC = tf.Variable([[7],[11]], tf.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reference, here is a table showing how different inputs lead to different `tensor` ranks:\n",
    "    \n",
    "![Tensor Rank Table](notebook_diagrams/tensorflow_rank_table.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Basic Math Operations with TensorFlow Tensors\n",
    "Like numpy `nd_array` objects, we can also use `tf.tensor` objects for doing mathematical operations in Python.\n",
    "\n",
    "**NOTE**: Recall that we can only see the output from these tensors, as well as convert these tensors to numpy, when eager execution is turned on.  If you receive errors stating these `tensor` objects cannot be converted to numpy `nd_array` objects, it is likely because you don't have eager execution turned on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1\n",
    "print(tf.add(1, 2))\n",
    "print(\"\\n\")\n",
    "\n",
    "print(tf.add([1, 2], [3, 4]))\n",
    "print(\"\\n\")\n",
    "\n",
    "print(tf.square(5))\n",
    "print(\"\\n\")\n",
    "\n",
    "print(tf.reduce_sum([1, 2, 3]))\n",
    "print(\"\\n\")\n",
    "\n",
    "# Operator overloading is also supported\n",
    "print(tf.square(2) + tf.square(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2\n",
    "x = tf.matmul([[1]], [[2, 3]])\n",
    "print(x)\n",
    "print(x.shape)\n",
    "print(x.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Converting Between Numpy and TensorFlow\n",
    "Numpy and TensorFlow are quite compatible with each other, which is extremely useful particularly when we can pre-process our data with numpy and/or OpenCV and then load this pre-processed data into TensorFlow.\n",
    "\n",
    "Calling the method `.numpy()` on a `tf.tensor` object (e.g. `tf.tensor.numpy()`) will convert the data type to a numpy `nd_array` (this could be relevant if we wanted to do post-processing of our data in numpy or openCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "ndarray = np.ones([3, 3])\n",
    "\n",
    "print(\"TensorFlow operations convert numpy arrays to Tensors automatically\")\n",
    "tensor = tf.multiply(ndarray, 42)\n",
    "print(tensor)\n",
    "\n",
    "\n",
    "print(\"\\n And NumPy operations convert Tensors to numpy arrays automatically\")\n",
    "print(np.add(tensor, 1))\n",
    "\n",
    "print(\"\\n The .numpy() method explicitly converts a Tensor to a numpy array\")\n",
    "print(tensor.numpy())\n",
    "print(\"Data type is now numpy nd_array! %s\" % (type(tensor.numpy())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Neural Network Models in TensorFlow\n",
    "Neural network models in TensorFlow are similar to what we've seen in Keras (since Keras is built on top of TensorFlow).  We'll explore two aspects of creating your own models with TensorFlow below:\n",
    "\n",
    "1. Creating custom layers\n",
    "\n",
    "2. Creating models using composition of layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Creating Custom Layers\n",
    "\n",
    "Material referenced from this [TensorFlow tutorial](https://www.tensorflow.org/tutorials/customization/custom_layers).\n",
    "\n",
    "The best way to implement your own layer is extending the `tf.keras.Layer` class and implementing the constructor method `* __init__` ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a customized Dense Layer\n",
    "class MyDenseLayer(tf.keras.layers.Layer):  # Notice how we use Keras here!\n",
    "  def __init__(self, num_outputs):\n",
    "    super(MyDenseLayer, self).__init__()\n",
    "    self.num_outputs = num_outputs\n",
    "\n",
    "  def build(self, input_shape):\n",
    "    self.kernel = self.add_variable(\"kernel\",\n",
    "                                    shape=[int(input_shape[-1]),\n",
    "                                           self.num_outputs])\n",
    "\n",
    "  def call(self, input):\n",
    "    return tf.matmul(input, self.kernel)\n",
    "\n",
    "# Make an instance of this layer\n",
    "layer = MyDenseLayer(10)\n",
    "\n",
    "# Now, make sure we call layer on something to \".build\" it (we can ignore output).\n",
    "_ = layer(tf.zeros([10, 5])) # Calling the layer `.builds` it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Creating Custom Models\n",
    "\n",
    "Material also referenced from [this TensorFlow tutorial](https://www.tensorflow.org/tutorials/customization/custom_layers).\n",
    "\n",
    "We can use the framework outlined in the class definition below to implement our own custom models.  Below, we will look at the mechanics of creating a **ResNet** block (as visualized below).\n",
    "\n",
    "![ResNet identity block](notebook_diagrams/resnet_identity_block.png)\n",
    "\n",
    "**NOTE**: The block of code below is meant only to serve as an example of how we can create different models, and isn't one you have to know specifically.  If you're interested in creating your own custom model, you can use the **general** structure of the code block: the `__init__` and `call` methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResnetIdentityBlock(tf.keras.Model):\n",
    "  \n",
    "  # This is called the constructor method, and determines what happens when we \"instantiate this object\"\n",
    "  def __init__(self, kernel_size, filters):\n",
    "    super(ResnetIdentityBlock, self).__init__(name='')\n",
    "    filters1, filters2, filters3 = filters\n",
    "\n",
    "    self.conv2a = tf.keras.layers.Conv2D(filters1, (1, 1))\n",
    "    self.bn2a = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "    self.conv2b = tf.keras.layers.Conv2D(filters2, kernel_size, padding='same')\n",
    "    self.bn2b = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "    self.conv2c = tf.keras.layers.Conv2D(filters3, (1, 1))\n",
    "    self.bn2c = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "  # This function defines how an input is mapped into a prediction\n",
    "  def call(self, input_tensor, training=False):\n",
    "    x = self.conv2a(input_tensor)\n",
    "    x = self.bn2a(x, training=training)\n",
    "    x = tf.nn.relu(x)\n",
    "\n",
    "    x = self.conv2b(x)\n",
    "    x = self.bn2b(x, training=training)\n",
    "    x = tf.nn.relu(x)\n",
    "\n",
    "    x = self.conv2c(x)\n",
    "    x = self.bn2c(x, training=training)\n",
    "\n",
    "    x += input_tensor\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "# Create an instance of this model\n",
    "block = ResnetIdentityBlock(1, [1, 2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Viewing a Model Summary\n",
    "Since the models we're calling are Keras models, we can again simply call `model.summary()` to view important parameters and characteristics about the models we create."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure we build the model first - can call it on an arbitrary input of correct input size\n",
    "_ = block(tf.zeros([1, 2, 3, 3])) \n",
    "\n",
    "# Now we can summarize\n",
    "block.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Creating Models in TensorFlow Using Keras\n",
    "This model creation process is identical to what we saw before (with the exception of placing a `tf.` in front of every keras object)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model in the exact same way as we did before!\n",
    "my_seq = tf.keras.Sequential([tf.keras.layers.Conv2D(1, (1, 1), input_shape=( None, None, 3)),\n",
    "                             tf.keras.layers.BatchNormalization(),\n",
    "                             tf.keras.layers.Conv2D(2, 1, padding='same'),\n",
    "                             tf.keras.layers.BatchNormalization(),\n",
    "                             tf.keras.layers.Conv2D(3, (1, 1)),\n",
    "                             tf.keras.layers.BatchNormalization()])\n",
    "\n",
    "# Remember to build the model!  Otherwise it will not run\n",
    "my_seq(tf.zeros([1, 2, 3, 3]))\n",
    "\n",
    "# Now we can summarize/train the model\n",
    "my_seq.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Training in TensorFlow - ConvNet Example\n",
    "Training, in particular custom training, is another reason to consider using TensorFlow for your next machine learning project.  In this section, we will explore an example of training both a pre-trained **Convolutional Neural Network (CNN)**.  We will walk through each section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Import Statements for ConvNet Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "# Make easier to read\n",
    "keras = tf.keras\n",
    "\n",
    "# Use for loading datasets\n",
    "!pip install tensorflow_datasets\n",
    "import tensorflow_datasets as tfds\n",
    "tfds.disable_progress_bar()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Load Dataset using tensorflow_datasets (tfds)\n",
    "We can directly download datasets from tensorflow using the package `tensorflow_datasets`, which we installed above.  We can split our dataset into training, testing, and evaluation, as we did so before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split weights for training/testing/evaluation\n",
    "SPLIT_WEIGHTS = (8, 1, 1)  # Numbers denote (train, validation, test)\n",
    "\n",
    "# Split dataset\n",
    "splits = tfds.Split.TRAIN.subsplit(weighted=SPLIT_WEIGHTS)  # Split according to our weights above\n",
    "\n",
    "# Load cats_vs_dogs dataset\n",
    "(raw_train, raw_validation, raw_test), metadata = tfds.load(\n",
    "    'cats_vs_dogs', split=list(splits),\n",
    "    with_info=True, as_supervised=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 View Datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print training data\n",
    "print(\"Training data: \\n %s \\n \\n\" % (raw_train))\n",
    "print(\"Type of training data: \\n %s \\n \\n\" % (type(raw_train)))\n",
    "\n",
    "# print validation data\n",
    "print(\"Validation data: \\n %s \\n \\n\" % (raw_validation))\n",
    "print(\"Type of validation data: \\n %s \\n \\n\" % (type(raw_validation)))\n",
    "\n",
    "# print testing data\n",
    "print(\"Test data: \\n %s \\n \\n\" % (raw_test))\n",
    "print(\"Type of validation data: \\n %s \\n \\n\" % (type(raw_validation)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 View Examples from Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_label_name = metadata.features['label'].int2str\n",
    "\n",
    "# Iteratively show images and labels\n",
    "for image, label in raw_train.take(2):\n",
    "  plt.figure()\n",
    "  plt.imshow(image)\n",
    "  plt.title(get_label_name(label))\n",
    "  plt.show()\n",
    "  plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5 Preprocess Data to Equal Size, and Scale Pixel Values\n",
    "This is a critical step for developing bug-free and effective datasets for deep learning pipelines.  Here, we will use the `tf.image.resize` function resize the image to the size of `(IMG_SIZE, IMG_SIZE)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 160 # All images will be resized to 160x160\n",
    "\n",
    "def format_example(image, label):\n",
    "  image = tf.cast(image, tf.float32)\n",
    "  image = (image/127.5) - 1\n",
    "  image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n",
    "  return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.6 Create Pre-trained ConvNet Model\n",
    "Here is where transfer learning will help us for solving our machine learning problem!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create image size to determine input shape of network\n",
    "IMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3)\n",
    "\n",
    "# Create the base model from the pre-trained model MobileNet V2\n",
    "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')  # Notice here that we're using weights from ImageNet!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.7 Create Datasets and Specify Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make datasets\n",
    "train = raw_train.map(format_example)\n",
    "validation = raw_validation.map(format_example)\n",
    "test = raw_test.map(format_example)\n",
    "\n",
    "# Specify hyperparameters\n",
    "BATCH_SIZE = 32\n",
    "SHUFFLE_BUFFER_SIZE = 1000\n",
    "\n",
    "# Make training batches\n",
    "train_batches = train.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "validation_batches = validation.batch(BATCH_SIZE)\n",
    "test_batches = test.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.8 Run Feature Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract image batch from dataset\n",
    "for image_batch, label_batch in train_batches.take(1):\n",
    "   print(\"Inspecting image batch!\")\n",
    "\n",
    "# Inspect an image batch\n",
    "print(\"Image batch shape: %s\" % (image_batch.shape))\n",
    "\n",
    "# Call the model on the image batch\n",
    "feature_batch = base_model(image_batch)\n",
    "print(\"Feature batch shape: %s\" % (feature_batch.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.9 Get Model Summary and Keep Weights Frozen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at the base model architecture\n",
    "print(base_model.summary())\n",
    "\n",
    "# Make sure weights are frozen\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.10 Add Final Layers to Transform Features into Predictions, and Stack Into Aggregate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First do a global averaging\n",
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "feature_batch_average = global_average_layer(feature_batch)\n",
    "print(feature_batch_average.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now make a final prediction layer\n",
    "prediction_layer = keras.layers.Dense(1)\n",
    "prediction_batch = prediction_layer(feature_batch_average)\n",
    "print(prediction_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, build the overall model\n",
    "model = tf.keras.Sequential([\n",
    "  base_model,\n",
    "  global_average_layer,\n",
    "  prediction_layer\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.11 Compile Model Using Keras and Summarize It"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify learning rate\n",
    "base_learning_rate = 0.0001\n",
    "\n",
    "# Compile model using Keras\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=base_learning_rate),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Summarize aggregated model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.12 Now We Are Ready to Train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset\n",
    "num_train, num_val, num_test = (\n",
    "  metadata.splits['train'].num_examples*weight/10\n",
    "  for weight in SPLIT_WEIGHTS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify hyperparameters for training\n",
    "initial_epochs = 10\n",
    "steps_per_epoch = round(num_train)//BATCH_SIZE\n",
    "validation_steps=20\n",
    "\n",
    "# Evaluate the model\n",
    "loss0,accuracy0 = model.evaluate(validation_batches, steps = validation_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now fit the model by training it\n",
    "history = model.fit(train_batches,\n",
    "                    epochs=initial_epochs,    \n",
    "                    validation_data=validation_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.13 Plot Evaluation Curves To Visualize Our Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.ylim([0,1.0])\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7: TensorFlow Datasets\n",
    "With Keras, we discussed the idea of using Image Data Generators.  Recall the main idea with data generators/datasets/dataloaders (we'll see all three of these terms with different machine learning packages, but they all really refer to the same concept) is that we can use the functionalities built out by these machine learning packages to efficiently and compactly feed in our input dataset into our training pipeline in a batched way.  \n",
    "\n",
    "For more information on TensorFlow datasets, see the [guide here](https://www.tensorflow.org/api_docs/python/tf/data/Dataset)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Configuring Devices (CPU and GPU) for TensorFlow\n",
    "TensorFlow has many capabilities for doing computations on both the CPU and GPU.  GPU computations are another feature of TensorFlow that contribute to its effectiveness as a deployable machine learning package.  Even without the use of GPUs, we can use parallel processing packages like [multiprocessing](https://docs.python.org/3.4/library/multiprocessing.html?highlight=process) to parallelize our machine learning computations using our CPUs.\n",
    "\n",
    "**NOTE**: The newest versions of TensorFlow will automatically install both the CPU and GPU versions of the package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check devices (source: https://stackoverflow.com/questions/38559755/how-to-get-current-available-gpus-in-tensorflow )\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we had GPUs on these machines, we could also run this command to receive information about GPU devices\n",
    "\n",
    "#GPU_command = \"nvidia-smi\"\n",
    "#os.system(GPU_command)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(We don't have any GPUs on these AWS machines, but if we did, it would list them above.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Conclusion\n",
    "TensorFlow is a powerful, efficient, and highly-scalable machine learning package for deep learning.  This tutorial covers only a very small fraction of the features and applications of this powerful framework, and we highly encourage you to explore all the capabilities this package offers.  \n",
    "\n",
    "You can find TensorFlow's online tutorials [here](https://www.tensorflow.org/tutorials).  Note that in addition to you being able to download the Jupyter notebooks that TensorFlow provides and run them on your own machine, you can also run TensorFlow's Jupyter notebooks through [Google Colab](https://colab.research.google.com/notebooks/intro.ipynb).  \n",
    "\n",
    "We hope this tutorial has provided you with a high-level idea of how TensorFlow works, why it works, and what it can be used for."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Other Recommended Concepts to Explore\n",
    "TensorFlow is a quite complicated library, and there are many additional features we encourage you to explore with it.  These include:\n",
    "\n",
    "1. [More TensorFlow Tutorials](https://www.tensorflow.org/tutorials)\n",
    "\n",
    "\n",
    "2. [Gradient Tape](https://www.tensorflow.org/api_docs/python/tf/GradientTape)\n",
    "\n",
    "\n",
    "3. [TensorFlow Agents](https://towardsdatascience.com/introduction-to-tf-agents-a-library-for-reinforcement-learning-in-tensorflow-68ab9add6ad6) (Deep Reinforcement Learning)\n",
    "\n",
    "\n",
    "4. [Tensorboard](https://www.tensorflow.org/tensorboard) (for plotting)\n",
    "\n",
    "\n",
    "5. [Cuda](https://developer.nvidia.com/pycuda) (GPU Package)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Extension: Want to Get More Practice with TensorFlow?  \n",
    "#### [Learn how to Train Your Own GAN in TensorFlow](tensorflow-tutorial-Cycle-GAN.ipynb) (notebook courtesy of TensorFlow 2.0: [Link Here](https://www.tensorflow.org/tutorials/generative/cyclegan)).\n",
    "\n",
    "![Cycle-GAN](ml_package_tutorials/notebook_diagrams/cyclegan.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
